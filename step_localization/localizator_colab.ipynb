{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f3407",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone --recursive https://github.com/perso00k/aml-2025-mistake-detection.git code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a86b3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11f840",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def import_features(source_dir, dest_dir):\n",
    "  import shutil\n",
    "  import os\n",
    "  from tqdm import tqdm\n",
    "\n",
    "  os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "  print(f\"Inizio copia da {source_dir} a {dest_dir}...\")\n",
    "\n",
    "  # Ottieni lista file .npz (o .pt se non li hai ancora convertiti)\n",
    "  files = [f for f in os.listdir(source_dir) if f.endswith('.npz') or f.endswith('.pt')]\n",
    "\n",
    "  if len(files) == 0:\n",
    "      print(\"ATTENZIONE: Nessun file .npz o .pt trovato! Controlla il percorso source_dir.\")\n",
    "  else:\n",
    "      for filename in tqdm(files):\n",
    "          src = os.path.join(source_dir, filename)\n",
    "          dst = os.path.join(dest_dir, filename)\n",
    "\n",
    "          # Copia solo se non esiste gi√† (cos√¨ se rilanci non perde tempo)\n",
    "          if not os.path.exists(dst):\n",
    "              shutil.copy2(src, dst)\n",
    "\n",
    "      print(\"Copia completata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f4a2f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "source_dir_video = \"/content/drive/MyDrive/AML_Project_resized_ds/features_PE_npz_1s_1s_final\"\n",
    "dest_dir_video = \"code/data/video/perception_encoder\"\n",
    "import_features(source_dir_video, dest_dir_video)\n",
    "\n",
    "source_dir_text = \"/content/drive/MyDrive/AML_Project_resized_ds/text_feature_PE\"\n",
    "dest_dir_text = \"code/data/graphs\"\n",
    "import_features(source_dir_text, dest_dir_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cac7ab",
   "metadata": {},
   "source": [
    "# SUBSTEP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c12e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python /content/code/step_localization/step_localizator_dtw.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ca6c0",
   "metadata": {},
   "source": [
    "# Valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c549b3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "PREDICTIONS_DIR = \"/content/code/data/localized_features\"\n",
    "# Questo √® il file delle VERIT√Ä (Ground Truth) fornito dai prof/dataset\n",
    "GROUND_TRUTH_FILE = \"/content/code/annotations/annotation_json/step_annotations.json\"\n",
    "\n",
    "def compute_frame_accuracy(pred_segments, gt_steps, video_duration):\n",
    "    \"\"\"\n",
    "    Calcola la Mean Over Frame (MoF) accuracy.\n",
    "    Confronta secondo per secondo se l'ID dello step predetto coincide con quello vero.\n",
    "    \"\"\"\n",
    "    # Arrotondiamo la durata per creare l'array dei secondi\n",
    "    duration_int = int(np.ceil(video_duration))\n",
    "    \n",
    "    # 0 = Background/Nessuno step (spesso ignorato o contato come errore se non annotato)\n",
    "    gt_array = np.zeros(duration_int, dtype=int) \n",
    "    pred_array = np.zeros(duration_int, dtype=int)\n",
    "    \n",
    "    # Riempiamo l'array con la Verit√† (Ground Truth)\n",
    "    for step in gt_steps:\n",
    "        sid = int(step['step_id'])\n",
    "        s = max(0, int(np.floor(step['start_time'])))\n",
    "        e = min(duration_int, int(np.ceil(step['end_time'])))\n",
    "        gt_array[s:e] = sid\n",
    "        \n",
    "    # Riempiamo l'array con le nostre Predizioni\n",
    "    for seg in pred_segments:\n",
    "        # seg √® [start, end, step_id]\n",
    "        sid = int(seg[2]) \n",
    "        s = max(0, int(np.floor(seg[0])))\n",
    "        e = min(duration_int, int(np.ceil(seg[1])))\n",
    "        pred_array[s:e] = sid\n",
    "        \n",
    "    # Calcoliamo l'accuracy solo dove c'√® un'annotazione valida nel GT\n",
    "    # (escludiamo il 'silenzio' background se non √® annotato esplicitamente)\n",
    "    mask = gt_array != 0\n",
    "    \n",
    "    if np.sum(mask) == 0:\n",
    "        return 0.0 # Nessun ground truth valido per questo video\n",
    "        \n",
    "    matches = (gt_array[mask] == pred_array[mask])\n",
    "    accuracy = np.mean(matches)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(GROUND_TRUTH_FILE):\n",
    "        print(f\"‚ùå Errore: Non trovo il file {GROUND_TRUTH_FILE}\")\n",
    "        print(\"Assicurati di aver caricato il file step_annotations.json nella cartella corretta.\")\n",
    "        return\n",
    "\n",
    "    with open(GROUND_TRUTH_FILE, 'r') as f:\n",
    "        gt_data = json.load(f)\n",
    "        \n",
    "    accuracies = []\n",
    "    processed_count = 0\n",
    "    missing_count = 0\n",
    "    \n",
    "    print(\"üìä Valutazione Accuratezza Localizzazione (Zero-Shot vs Ground Truth)...\")\n",
    "    \n",
    "    for video_id, info in tqdm(gt_data.items()):\n",
    "        # Cerca il file di predizione corrispondente (generato dal tuo script localize)\n",
    "        pred_path = os.path.join(PREDICTIONS_DIR, f\"{video_id}.npz\")\n",
    "        \n",
    "        # Se non abbiamo processato questo video (es. mancavano feature), saltiamo\n",
    "        if not os.path.exists(pred_path):\n",
    "            missing_count += 1\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Carica predizione\n",
    "            data = np.load(pred_path)\n",
    "            if 'segments' not in data: \n",
    "                continue\n",
    "            \n",
    "            pred_segments = data['segments'] # Array Nx3: [start, end, step_id]\n",
    "            gt_steps = info['steps']\n",
    "            \n",
    "            # Calcola la durata massima per dimensionare gli array\n",
    "            if len(pred_segments) > 0:\n",
    "                max_pred = np.max(pred_segments[:, 1])\n",
    "            else: max_pred = 0\n",
    "            \n",
    "            max_gt = 0\n",
    "            if gt_steps:\n",
    "                max_gt = max([s['end_time'] for s in gt_steps])\n",
    "                \n",
    "            duration = max(max_pred, max_gt) + 5 # +5 secondi di margine\n",
    "            \n",
    "            # Calcola score per questo video\n",
    "            acc = compute_frame_accuracy(pred_segments, gt_steps, duration)\n",
    "            accuracies.append(acc)\n",
    "            processed_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            # print(f\"Errore su {video_id}: {e}\")\n",
    "            pass\n",
    "        \n",
    "    if processed_count == 0:\n",
    "        print(\"‚ùå Nessun video valutato. Hai eseguito localize_steps_dtw.py?\")\n",
    "        print(f\"Video mancanti: {missing_count}\")\n",
    "    else:\n",
    "        mean_acc = np.mean(accuracies) * 100\n",
    "        print(f\"\\n‚úÖ Valutazione Completata su {processed_count} video.\")\n",
    "        print(f\"üö´ Video mancanti/saltati: {missing_count}\")\n",
    "        print(f\"üìà Mean Frame Accuracy (MoF): {mean_acc:.2f}%\")\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"INTERPRETAZIONE:\")\n",
    "        print(\" < 15%: Localizzazione scarsa\")\n",
    "        print(\" 20-30%: Buon risultato per Zero-Shot (senza training)\")\n",
    "        print(\" > 40%: Risultato eccellente\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
